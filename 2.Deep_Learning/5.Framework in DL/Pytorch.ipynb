{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial\n",
    "\n",
    "**Pushed by Facebook and designed for Python GPU running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]])\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.]])\n",
      "tensor([[ 1.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.6230,  0.9187,  0.2897],\n",
      "        [ 0.9383,  0.3139,  0.5042],\n",
      "        [ 0.6413,  0.7564,  0.2275],\n",
      "        [ 0.8676,  0.6462,  0.8919],\n",
      "        [ 0.4324,  0.8229,  0.6536]])\n",
      "tensor([[-1.3840, -0.0320,  0.2032],\n",
      "        [-0.4949, -0.8910,  1.6536],\n",
      "        [-0.9650, -0.8319, -0.1394],\n",
      "        [-1.4508,  0.0410,  0.6471],\n",
      "        [ 0.8073,  1.3711, -1.1532]])\n",
      "tensor([[ 1.,  1.,  1.,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  0.,  0.,  0.]])\n",
      "tensor([[[ 1.,  1.,  1.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.],\n",
      "         [ 0.,  0.,  0.]]])\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.]])\n",
      "[1 2 4]\n",
      "tensor([ 1,  2,  4])\n",
      "[1 2 4]\n",
      "tensor([ 1.,  2.,  4.])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.ones(5,3)\n",
    "x2 = torch.zeros(5,3)\n",
    "x3 = torch.eye(4)\n",
    "x4 = torch.rand(5,3)\n",
    "x5 = torch.randn(5,3)\n",
    "\n",
    "#Concatenate x1 and x2 at axis 1\n",
    "x6 = torch.cat((x1,x2),1)\n",
    "#Stack x1 and x2 at axis 1\n",
    "x7 = torch.stack((x1,x2),1)\n",
    "#reshape\n",
    "x8 = x1.view(-1)\n",
    "x9 = x2.expand(5,3)\n",
    "\n",
    "#Numpy relation\n",
    "a1 = np.array([1,2,4])\n",
    "x10 = torch.from_numpy(a1)\n",
    "a2 = x10.numpy()\n",
    "a3 = [1,2,4]\n",
    "x11 = torch.Tensor(a3)\n",
    "\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(x3)\n",
    "print(x4)\n",
    "print(x5)\n",
    "print(x6)\n",
    "print(x7)\n",
    "print(x8)\n",
    "print(x9)\n",
    "print(a1)\n",
    "print(x10)\n",
    "print(a2)\n",
    "print(x11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "y1 = x1+x2\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "#Variable includes data(), grad(), creator(), backward()\n",
    "#requires_grad: Update or not,  volatile: need outcome but don't update\n",
    "a = Variable(x1, requires_grad=True)\n",
    "b = Variable(x2, volatile=True)\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Computation\n",
    "\n",
    "1. 建立Variable\n",
    "2. 建立optimizer\n",
    "\n",
    "Train\n",
    "1. 呼叫optimizer的zero_grad歸零grads\n",
    "2. 操作現有參數得到loss\n",
    "3. 呼叫loss backward算出所有梯度\n",
    "4. optimizer.step更新梯度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30.)\n",
      "tensor(27.)\n",
      "tensor(24.0000)\n",
      "tensor(21.0000)\n",
      "tensor(18.0000)\n",
      "tensor(15.0000)\n",
      "tensor(12.0000)\n",
      "tensor(9.0000)\n",
      "tensor(6.0000)\n",
      "tensor(3.0000)\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "x1 = torch.ones(5,3)\n",
    "x2 = torch.ones(5,3)\n",
    "a = Variable(x1, requires_grad=True)\n",
    "b = Variable(x2, requires_grad=True)\n",
    "\n",
    "optimizer = SGD([a,b], lr=0.1)\n",
    "\n",
    "#run for loop\n",
    "for _ in range(10):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = (a+b).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Network \n",
    "\n",
    "1. 先用class建立model\n",
    "2. 建立optimizer\n",
    "\n",
    "train\n",
    "1. 呼叫optimizer的zero_grad歸零grads\n",
    "2. 操作現有參數得到loss\n",
    "3. 呼叫loss backward算出所有梯度\n",
    "4. optimizer.step更新梯度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x10d526f68>\n"
     ]
    }
   ],
   "source": [
    "#Define class for model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  #Input channel, Output channel, 5x5 kernel size\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120) #Input, Output\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2)) # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# torchvision数据集的输出是在[0, 1]范围内的PILImage图片。\n",
    "# 我们此处使用归一化的方法将其转化为Tensor，数据范围为[-1, 1]\n",
    "\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, \n",
    "                                          shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.304\n",
      "[1,  4000] loss: 2.301\n",
      "[1,  6000] loss: 2.298\n",
      "[1,  8000] loss: 2.291\n",
      "[1, 10000] loss: 2.272\n",
      "[1, 12000] loss: 2.192\n",
      "[2,  2000] loss: 2.082\n",
      "[2,  4000] loss: 2.014\n",
      "[2,  6000] loss: 1.955\n",
      "[2,  8000] loss: 1.922\n",
      "[2, 10000] loss: 1.889\n",
      "[2, 12000] loss: 1.854\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in range(2):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, lables = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999: # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

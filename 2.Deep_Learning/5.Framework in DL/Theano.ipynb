{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano import function\n",
    "from theano import pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "#1. Define parameters\n",
    "X = T.dscalar('x')\n",
    "Y = T.dscalar('y')\n",
    "x = T.dmatrix('x')\n",
    "y = T.dmatrix('y')\n",
    "a, b = T.dmatrices('a','b')\n",
    "\n",
    "Z = X+Y\n",
    "f = function([X,Y], Z)\n",
    "print(f(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88079708 0.95257413]\n",
      " [0.95257413 0.99330715]]\n"
     ]
    }
   ],
   "source": [
    "s = 1/(1+T.exp(-x))\n",
    "f1 = function([x], s)\n",
    "print(f1([[2,3],[3,5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.,  0.],\n",
      "       [-1., -2.]]), array([[1., 0.],\n",
      "       [1., 2.]]), array([[1., 0.],\n",
      "       [1., 4.]])]\n"
     ]
    }
   ],
   "source": [
    "diff = a-b\n",
    "absdiff = abs(a-b)\n",
    "diff_square = absdiff ** 2\n",
    "f2 = function([a,b], [diff,absdiff,diff_square])\n",
    "print(f2(np.ones((2,2)), np.arange(4).reshape((2,2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define variable\n",
    "state = theano.shared(np.array(0,dtype=np.float64), 'state')\n",
    "inc = T.scalar('inc', dtype=state.dtype)\n",
    "accumulator = function([inc], state, updates=[(state, state+inc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "10.0\n",
      "11.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "print(state.get_value())\n",
    "accumulator(10)\n",
    "print(state.get_value())\n",
    "accumulator(1)\n",
    "print(state.get_value())\n",
    "state.set_value(1)\n",
    "accumulator(2)\n",
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "#Temporarily replace hsared variable with another value in another function\n",
    "a = T.scalar(dtype=state.dtype)\n",
    "b = state*2+inc\n",
    "accumulator1 = function([inc,a], b, givens=[(state, a)])\n",
    "print(accumulator1(2,3))\n",
    "\n",
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Define layers\n",
    "class Layer(object):\n",
    "    def __init__(self, inputs, in_size, out_size, activation_function=None):\n",
    "        self.W = theano.shared(np.random.normal(0, 1, (in_size, out_size)))\n",
    "        self.b = theano.shared(np.zeros((out_size, )) + 0.1)\n",
    "        self.Wx_plus_b = T.dot(inputs, self.W) + self.b\n",
    "        self.activation_function = activation_function\n",
    "        if activation_function is None:\n",
    "            self.outputs = self.Wx_plus_b\n",
    "        else:\n",
    "            self.outputs = self.activation_function(self.Wx_plus_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Define layers\n",
    "class Layer(object):\n",
    "    def __init__(self, inputs, in_size, out_size, activation_function=None):\n",
    "        self.W = theano.shared(np.random.normal(0, 1, (in_size, out_size)))\n",
    "        self.b = theano.shared(np.zeros((out_size, )) + 0.1)\n",
    "        self.Wx_plus_b = T.dot(inputs, self.W) + self.b\n",
    "        self.activation_function = activation_function\n",
    "        if activation_function is None:\n",
    "            self.outputs = self.Wx_plus_b\n",
    "        else:\n",
    "            self.outputs = self.activation_function(self.Wx_plus_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Define parameters and calculation\n",
    "x = T.dmatrix('x')\n",
    "y = T.dmatrix('y')\n",
    "\n",
    "l1 = Layer(x, 1, 10, T.nnet.relu)\n",
    "l2 = Layer(l1.outputs, 10, 1, None)\n",
    "\n",
    "cost = T.mean(T.square(l2.outputs-y))\n",
    "gW1, gb1, gW2, gb2 = T.grad(cost, [l1.W, l1.b, l2.W, l2.b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Define train\n",
    "# apply gradient descent\n",
    "learning_rate = 0.05\n",
    "train = theano.function(\n",
    "    inputs=[x, y],\n",
    "    outputs=cost,\n",
    "    updates=[(l1.W, l1.W - learning_rate * gW1),\n",
    "             (l1.b, l1.b - learning_rate * gb1),\n",
    "             (l2.W, l2.W - learning_rate * gW2),\n",
    "             (l2.b, l2.b - learning_rate * gb2)])\n",
    "# prediction\n",
    "predict = theano.function(inputs=[x], outputs=l2.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make up some fake data\n",
    "x_data = np.linspace(-1, 1, 300)[:, np.newaxis]\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise        # y = x^2 - 0.5 + wihtenoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.0033993545126246587\n",
      "loss =  0.003366331468226002\n",
      "loss =  0.003334997770550666\n",
      "loss =  0.003305281066661631\n",
      "loss =  0.0032714251269618353\n",
      "loss =  0.003243027361688797\n",
      "loss =  0.003218678781197237\n",
      "loss =  0.0031965899769304295\n",
      "loss =  0.003173364033589988\n",
      "loss =  0.0031526951627376953\n",
      "loss =  0.003133079630045783\n",
      "loss =  0.003115943042568304\n",
      "loss =  0.003101909201799517\n",
      "loss =  0.0030897221269296418\n",
      "loss =  0.003079004012166864\n",
      "loss =  0.0030674528851822353\n",
      "loss =  0.003055307097527482\n",
      "loss =  0.0030448543067851342\n",
      "loss =  0.0030371360666536945\n",
      "loss =  0.0030306063664698917\n"
     ]
    }
   ],
   "source": [
    "#4. Run Training\n",
    "for i in range(1000):\n",
    "    # training\n",
    "    err = train(x_data, y_data)\n",
    "    if i % 50 == 0:\n",
    "        print('loss = ',err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Make some data\n",
    "feat = 784\n",
    "N = 200\n",
    "\n",
    "x_data = np.random.randn(N, feat)\n",
    "y_data = np.random.randint(size=N, low=0, high=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Define parameters\n",
    "X = T.dmatrix('X')\n",
    "Y = T.dvector('Y')\n",
    "\n",
    "W = theano.shared(np.random.randn(feat), 'W')\n",
    "b = theano.shared(0., 'b')\n",
    "\n",
    "p_1 = T.nnet.sigmoid(T.dot(X,W)+b)\n",
    "pred = p_1 > 0.5\n",
    "xent = -(Y*T.log(p_1)+(1-Y)*T.log(1-p_1))\n",
    "cost = xent.mean() + 0.01 * (W**2).sum()\n",
    "gW, gb = T.grad(cost, [W,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Define train\n",
    "train = function([X, Y], outputs=[pred, xent.mean()], updates=((W,W-0.1*gW),(b,b-0.1*gb)))\n",
    "predict = function([X], outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.024335293975827142\n",
      "loss =  0.024334963861475486\n",
      "loss =  0.024334649533150357\n",
      "loss =  0.024334349458357246\n",
      "loss =  0.024334062273674677\n",
      "loss =  0.024333786773224165\n",
      "loss =  0.024333521895151488\n",
      "loss =  0.02433326670737744\n",
      "loss =  0.02433302039345535\n",
      "loss =  0.024332782239066316\n",
      "loss =  0.024332551619465518\n",
      "loss =  0.024332327988037895\n",
      "loss =  0.0243321108660187\n",
      "loss =  0.02433189983336484\n",
      "loss =  0.024331694520721432\n",
      "loss =  0.024331494602401808\n",
      "loss =  0.02433129979028874\n",
      "loss =  0.024331109828560394\n",
      "loss =  0.02433092448914631\n",
      "loss =  0.024330743567824137\n"
     ]
    }
   ],
   "source": [
    "#4. Run Training\n",
    "for i in range(1000):\n",
    "    # training\n",
    "    pred, err = train(x_data, y_data)\n",
    "    if i % 50 == 0:\n",
    "        print('loss = ',err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
